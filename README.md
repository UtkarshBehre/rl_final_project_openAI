# DQN, DDQN on OpenAI gym environments

Environments Planned:

without cnn
* cartpole CartPole-v1
* Acrobot  Acrobot-v1
* pendulum Pendulum-v0

with cnn
* space invaders   SpaceInvaders-v0
* Lunar Landing    LunarLander-v2    LunarLanderContinuous-v2
* CarRacing        CarRacing-v0

Important Links
* openAI atari: https://gym.openai.com/envs/#atari
* openAI classic controls: https://gym.openai.com/envs/#classic_control

# Agents list

1. dqn_ddqn_img_agent
2. dqn_ddqn_nonimg_agent
3. reinforce_img_agent
4. reinforce_nonimg_agent
5. a2c_img_agent
6. a2c_nonimg_agent
7. ppo_img_agent
8. ppo_nonimg_agent

environment.py makes img and nonimg environments


https://web.stanford.edu/class/psych209/Readings/MnihEtAlHassibis15NatureControlDeepRL.pdf